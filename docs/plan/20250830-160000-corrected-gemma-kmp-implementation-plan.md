# üî¨ HazardHawk Local AI Implementation Plan - **CORRECTED ARCHITECTURE**

**Generated:** 2025-08-30 16:00:00  
**Status:** Ready for Implementation  
**Target Platform:** Kotlin Multiplatform (Android, iOS, Desktop, Web)  
**AI Solution:** ONNX Runtime + Google Gemma 2B ONNX Model

---

## üö® **Critical Architecture Correction**

**ORIGINAL PLAN ISSUE:** Flutter Gemma plugin cannot be used with Kotlin Multiplatform projects.

**CORRECTED SOLUTION:** Use ONNX Runtime with ONNX-converted Gemma models for true cross-platform KMP compatibility.

---

## üìã Executive Summary

This **corrected** implementation plan integrates local AI capabilities into HazardHawk's Kotlin Multiplatform architecture using **ONNX Runtime** with **Gemma 2B ONNX models**. This approach provides true cross-platform compatibility while maintaining offline-first AI processing for construction safety analysis.

### üéØ Strategic Advantages
- **True Cross-Platform:** Native KMP implementation works on Android, iOS, Desktop, and Web
- **ONNX Ecosystem:** Mature, production-ready runtime with extensive platform support
- **Model Flexibility:** Convert any Gemma variant to ONNX format as needed
- **Performance:** Platform-optimized execution with GPU acceleration where available
- **Memory Efficient:** ~1.5GB model footprint with quantization options

### ‚úÖ Recommendation
**PROCEED** with ONNX Runtime + Gemma 2B ONNX implementation using Kotlin Multiplatform expect/actual patterns.

---

## üèóÔ∏è Corrected Technical Architecture

### High-Level Component Design

```mermaid
graph TB
    A[Photo Capture<br/>Camera + Metadata] --> B[AIProcessingPipeline]
    
    B --> C[OnDeviceAnalyzer<br/>ML Kit - 1s timeout]
    B --> D[ONNXGemmaAnalyzer<br/>ONNX Runtime - 3s timeout]
    B --> E[CloudAnalyzer<br/>Gemini - 10s timeout]
    
    C --> F[Result Merger]
    D --> F
    E --> F
    
    F --> G[Enhanced Tag Recommendations]
    G --> H[Construction Safety Assessment]
    
    D --> I[Platform-Specific<br/>ONNX Runtime Implementations]
    I --> J[Android<br/>ONNX Runtime AAR]
    I --> K[iOS<br/>ONNX Runtime iOS]
    I --> L[Desktop<br/>ONNX Runtime JVM]
    I --> M[Web<br/>ONNX.js]
```

### Core Interfaces (expect/actual Pattern)

```kotlin
// shared/src/commonMain/kotlin/com/hazardhawk/ai/ONNXGemmaAnalyzer.kt
expect class ONNXGemmaAnalyzer {
    suspend fun initialize(): Boolean
    suspend fun analyzeImage(imageData: ByteArray): GemmaAnalysis
    suspend fun analyzeImageWithText(imageData: ByteArray, textPrompt: String): GemmaAnalysis
    fun isModelLoaded(): Boolean
    suspend fun release()
}

@Serializable
data class GemmaAnalysis(
    val hazardsDetected: List<Hazard> = emptyList(),
    val ppeCompliance: PPECompliance = PPECompliance(),
    val suggestedTags: List<String> = emptyList(),
    val confidence: Float = 0.0f,
    val processingTime: Long = 0L,
    val modelVersion: String = "gemma-2b-onnx",
    val analysisDetails: String? = null
)
```

### Platform-Specific Implementations

#### Android Implementation (Using ONNX Runtime AAR)

```kotlin
// shared/src/androidMain/kotlin/com/hazardhawk/ai/ONNXGemmaAnalyzer.kt
import ai.onnxruntime.*

actual class ONNXGemmaAnalyzer(
    private val context: android.content.Context
) {
    private var ortEnvironment: OrtEnvironment? = null
    private var ortSession: OrtSession? = null
    
    actual suspend fun initialize(): Boolean {
        return withContext(Dispatchers.IO) {
            try {
                // Initialize ONNX Runtime Environment
                ortEnvironment = OrtEnvironment.getEnvironment()
                
                // Load model from assets
                val modelBytes = context.assets.open("gemma2b_construction_safety.onnx").readBytes()
                
                // Create session with Android optimizations
                val sessionOptions = OrtSession.SessionOptions().apply {
                    // Use Android NNAPI if available
                    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.Q) {
                        addNnapi()
                    }
                    // CPU optimizations
                    setIntraOpNumThreads(4)
                    setSessionGraphOptimizationLevel(GraphOptimizationLevel.ORT_ENABLE_ALL)
                }
                
                ortSession = ortEnvironment!!.createSession(modelBytes, sessionOptions)
                true
            } catch (e: Exception) {
                Log.e("ONNXGemmaAnalyzer", "Failed to initialize", e)
                false
            }
        }
    }
    
    actual suspend fun analyzeImage(imageData: ByteArray): GemmaAnalysis {
        return withTimeout(3000L) {
            val session = ortSession ?: throw IllegalStateException("Model not initialized")
            
            try {
                // Preprocess image
                val preprocessedImage = preprocessImageForGemma(imageData)
                
                // Create input tensors
                val inputTensor = OnnxTensor.createTensorFromBuffer(
                    ortEnvironment!!,
                    preprocessedImage,
                    longArrayOf(1, 3, 224, 224) // NCHW format
                )
                
                // Run inference
                val results = session.run(mapOf("input_image" to inputTensor))
                
                // Parse outputs
                parseConstructionSafetyResults(results)
            } catch (e: Exception) {
                Log.e("ONNXGemmaAnalyzer", "Inference failed", e)
                GemmaAnalysis(confidence = 0.0f)
            }
        }
    }
    
    private fun preprocessImageForGemma(imageData: ByteArray): FloatArray {
        // Convert image to RGB float array normalized to [0, 1]
        val bitmap = BitmapFactory.decodeByteArray(imageData, 0, imageData.size)
        val resizedBitmap = Bitmap.createScaledBitmap(bitmap, 224, 224, true)
        
        val pixels = IntArray(224 * 224)
        resizedBitmap.getPixels(pixels, 0, 224, 0, 0, 224, 224)
        
        return FloatArray(3 * 224 * 224) { i ->
            val pixelIndex = i / 3
            val channel = i % 3
            val pixel = pixels[pixelIndex]
            
            when (channel) {
                0 -> ((pixel shr 16) and 0xFF) / 255.0f // Red
                1 -> ((pixel shr 8) and 0xFF) / 255.0f  // Green
                2 -> (pixel and 0xFF) / 255.0f          // Blue
                else -> 0.0f
            }
        }
    }
}
```

#### iOS Implementation (Using ONNX Runtime iOS)

```kotlin
// shared/src/iosMain/kotlin/com/hazardhawk/ai/ONNXGemmaAnalyzer.kt
actual class ONNXGemmaAnalyzer {
    private var ortSession: COpaquePointer? = null
    
    actual suspend fun initialize(): Boolean {
        return withContext(Dispatchers.IO) {
            // Use iOS-specific ONNX Runtime C API
            // Load model from iOS bundle
            val modelPath = NSBundle.mainBundle.pathForResource("gemma2b_construction_safety", "onnx")
            // Initialize with iOS Core ML delegate if available
            ortSession = createOrtSessionIOS(modelPath)
            ortSession != null
        }
    }
    
    actual suspend fun analyzeImage(imageData: ByteArray): GemmaAnalysis {
        // iOS-specific implementation using Core Graphics for preprocessing
        // and ONNX Runtime iOS for inference
        TODO("Implement iOS-specific ONNX Runtime integration")
    }
}

// iOS-specific helper functions
private external fun createOrtSessionIOS(modelPath: String?): COpaquePointer?
private external fun runInferenceIOS(session: COpaquePointer, imageData: ByteArray): FloatArray
```

---

## üöÄ Corrected Implementation Roadmap

### Phase 1: ONNX Runtime Integration (Week 1-2)

#### Dependencies and Setup

**Android (build.gradle.kts)**
```kotlin
dependencies {
    implementation("com.microsoft.onnxruntime:onnxruntime-android:1.19.2")
    
    // For GPU acceleration (optional)
    implementation("com.microsoft.onnxruntime:onnxruntime-extensions-android:0.11.0")
}
```

**iOS (via CocoaPods)**
```ruby
# Add to shared module's iOS configuration
pod 'onnxruntime-c', '~> 1.19.2'
pod 'onnxruntime-objc', '~> 1.19.2'
```

**Desktop (JVM)**
```kotlin
dependencies {
    implementation("com.microsoft.onnxruntime:onnxruntime:1.19.2")
    implementation("com.microsoft.onnxruntime:onnxruntime_gpu:1.19.2") // For CUDA support
}
```

#### Model Acquisition and Conversion

1. **Download Gemma 2B PyTorch Model**
   ```bash
   # Using Hugging Face Hub
   python -c "
   from transformers import AutoModel
   model = AutoModel.from_pretrained('google/gemma-2b')
   model.save_pretrained('./gemma-2b-pytorch')
   "
   ```

2. **Convert to ONNX Format**
   ```bash
   # Convert PyTorch to ONNX
   python convert_gemma_to_onnx.py \
     --model_path ./gemma-2b-pytorch \
     --output_path ./gemma2b_construction_safety.onnx \
     --opset_version 17 \
     --optimize_for_mobile
   ```

3. **Optimize for Mobile**
   ```bash
   # Use ONNX Runtime's optimization tools
   python -m onnxruntime.tools.convert_onnx_models_to_ort \
     --optimization_style Fixed \
     --output_dir ./optimized_models \
     ./gemma2b_construction_safety.onnx
   ```

### Phase 2: Construction Safety Prompting (Week 3-4)

#### Prompt Engineering for Vision-Language Model

```kotlin
object ConstructionSafetyPrompts {
    fun buildSafetyAnalysisPrompt(context: SafetyContext): String {
        return """
        You are an OSHA-certified construction safety expert. Analyze this construction site image.
        
        CONTEXT:
        - Project Type: ${context.projectType}
        - Weather: ${context.weather}  
        - Time: ${context.timeOfDay}
        - Location: ${context.location}
        
        ANALYZE FOR:
        1. PPE Compliance (hard hats, safety vests, boots, gloves, eye protection)
        2. Fall Protection (guardrails, harnesses, scaffolding safety)
        3. Electrical Hazards (exposed wiring, improper grounding)
        4. Site Housekeeping (debris, trip hazards, material storage)
        5. Equipment Safety (machine guards, proper operation)
        
        RESPOND IN JSON FORMAT:
        {
            "hazards": [
                {
                    "type": "fall_protection",
                    "severity": "high|medium|low",
                    "description": "Specific hazard description",
                    "osha_code": "1926.501",
                    "location": "Area in image where hazard is located"
                }
            ],
            "ppe_compliance": {
                "hard_hat": {"present": true, "compliant": true, "confidence": 0.95},
                "safety_vest": {"present": true, "compliant": false, "confidence": 0.87},
                "safety_boots": {"present": true, "compliant": true, "confidence": 0.92}
            },
            "recommended_actions": [
                "Secure loose materials near work area",
                "Add warning signage for electrical hazard",
                "Install temporary guardrails"
            ],
            "overall_risk": "high|medium|low",
            "confidence": 0.87
        }
        """.trimIndent()
    }
}
```

### Phase 3: Enhanced Tag Integration (Week 5-6)

#### AI-Enhanced Tag Recommendation Engine

```kotlin
class AIEnhancedTagRecommendationEngine(
    private val constructionAnalyzer: ONNXGemmaAnalyzer,
    private val existingTagEngine: TagRecommendationEngine
) {
    suspend fun generateEnhancedRecommendations(
        photoId: String,
        imageData: ByteArray,
        metadata: PhotoMetadata,
        userContext: UserContext
    ): List<TagRecommendation> {
        
        // Get AI analysis
        val safetyAnalysis = constructionAnalyzer.analyzeImage(imageData)
        
        // Convert AI findings to tag suggestions
        val aiSuggestedTags = mapSafetyAnalysisToTags(safetyAnalysis)
        
        // Merge with existing pattern-based recommendations
        return mergeAndScoreRecommendations(
            aiTags = aiSuggestedTags,
            patternTags = existingTagEngine.generateQuickSuggestions(
                userContext.userId, 
                aiSuggestedTags.map { it.category }
            ),
            userHistory = userContext.tagHistory,
            aiConfidence = safetyAnalysis.confidence
        )
    }
    
    private fun mapSafetyAnalysisToTags(analysis: GemmaAnalysis): List<TagRecommendation> {
        val recommendations = mutableListOf<TagRecommendation>()
        
        // Map hazards to tags
        analysis.hazardsDetected.forEach { hazard ->
            recommendations.add(TagRecommendation(
                tag = "hazard_${hazard.type}",
                confidence = hazard.confidence,
                source = "AI_VISION",
                reasoning = hazard.description,
                oshaCode = hazard.oshaCode
            ))
        }
        
        // Map PPE compliance to tags
        analysis.ppeCompliance.violations.forEach { violation ->
            recommendations.add(TagRecommendation(
                tag = "ppe_violation_${violation.type}",
                confidence = violation.confidence,
                source = "AI_VISION",
                reasoning = "PPE not properly worn or missing"
            ))
        }
        
        return recommendations
    }
}
```

---

## üß™ Testing Strategy

### ONNX Model Validation Tests

```kotlin
class ONNXGemmaAnalyzerTest {
    
    @Test
    fun `model initialization should succeed with valid model`() = runTest {
        val analyzer = ONNXGemmaAnalyzer(testContext)
        val initialized = analyzer.initialize()
        assertTrue(initialized)
        assertTrue(analyzer.isModelLoaded())
    }
    
    @Test
    fun `analyze image should detect PPE violations with minimum accuracy`() = runTest {
        val analyzer = ONNXGemmaAnalyzer(testContext)
        analyzer.initialize()
        
        // Test with known PPE violation images
        val testImages = constructionSafetyTestDataset.getPPEViolationImages()
        var correctDetections = 0
        
        testImages.forEach { testCase ->
            val result = analyzer.analyzeImage(testCase.imageBytes)
            
            // Validate PPE detection
            val hardhatViolation = result.ppeCompliance.violations
                .any { it.type == PPEType.HARD_HAT }
            
            if (hardhatViolation == testCase.expectedHardhatViolation) {
                correctDetections++
            }
            
            // Performance assertions
            assertTrue(result.confidence > 0.5f)
            assertTrue(result.processingTime < 5000L)
        }
        
        val accuracy = correctDetections.toFloat() / testImages.size
        assertTrue("PPE detection accuracy should be >= 70%", accuracy >= 0.70f)
    }
    
    @Test
    fun `memory usage should stay within limits during inference`() = runTest {
        val analyzer = ONNXGemmaAnalyzer(testContext)
        analyzer.initialize()
        
        val initialMemory = getUsedMemory()
        
        // Run multiple inferences
        repeat(10) {
            val testImage = generateTestConstructionImage()
            analyzer.analyzeImage(testImage)
        }
        
        val finalMemory = getUsedMemory()
        val memoryIncrease = finalMemory - initialMemory
        
        // Memory increase should be < 100MB for 10 inferences
        assertTrue("Memory increase should be minimal", memoryIncrease < 100_000_000)
    }
}
```

---

## üìä Performance Benchmarks

### Target Performance Metrics

| Device Category | Expected Inference Time | Memory Usage | Accuracy Target |
|-----------------|------------------------|--------------|-----------------|
| High-End Android (Galaxy S24) | 2.0-3.0s | 2.5GB peak | ‚â•85% hazard detection |
| Mid-Range Android (Galaxy A54) | 3.0-5.0s | 3.0GB peak | ‚â•80% hazard detection |
| iPhone 14 Pro | 1.5-2.5s | 2.0GB peak | ‚â•85% hazard detection |
| iPad Pro M2 | 1.0-2.0s | 2.5GB peak | ‚â•90% hazard detection |

---

## üìÅ Implementation Files

### Files to Create

| File Path | Purpose | Priority |
|-----------|---------|----------|
| `shared/src/commonMain/kotlin/com/hazardhawk/ai/ONNXGemmaAnalyzer.kt` | Common interface | HIGH |
| `shared/src/androidMain/kotlin/com/hazardhawk/ai/ONNXGemmaAnalyzer.kt` | Android ONNX implementation | HIGH |
| `shared/src/iosMain/kotlin/com/hazardhawk/ai/ONNXGemmaAnalyzer.kt` | iOS ONNX implementation | HIGH |
| `shared/src/desktopMain/kotlin/com/hazardhawk/ai/ONNXGemmaAnalyzer.kt` | Desktop ONNX implementation | MEDIUM |
| `shared/src/commonMain/kotlin/com/hazardhawk/ai/ConstructionSafetyPrompts.kt` | Prompt engineering | HIGH |
| `scripts/convert_gemma_to_onnx.py` | Model conversion script | HIGH |

### Files to Modify

| File Path | Changes Required | Impact |
|-----------|------------------|---------|
| `HazardHawk/shared/src/commonMain/kotlin/com/hazardhawk/ai/AIProcessingPipeline.kt` | Add ONNX Gemma step | HIGH |
| `HazardHawk/androidApp/build.gradle.kts` | Add ONNX Runtime dependency | MEDIUM |
| `HazardHawk/shared/src/commonMain/kotlin/com/hazardhawk/di/SharedModule.kt` | Add ONNX DI config | MEDIUM |

---

## ‚ö†Ô∏è Risk Mitigation

### Updated Risk Assessment

| Risk | Impact | Probability | Mitigation |
|------|---------|-------------|------------|
| ONNX Model Size (2.5GB) | HIGH | LOW | Use quantized INT8 models, progressive loading |
| Cross-Platform ONNX Runtime Issues | MEDIUM | MEDIUM | Extensive testing, fallback to cloud AI |
| Model Conversion Quality Loss | MEDIUM | MEDIUM | Validate accuracy post-conversion, fine-tune |
| Performance on Budget Devices | HIGH | HIGH | CPU-only fallback, model quantization |

---

## üéØ Success Criteria

- ‚úÖ **Cross-Platform Compatibility:** Single codebase works on Android, iOS, Desktop
- ‚úÖ **Performance:** <5s inference time on mid-range devices
- ‚úÖ **Accuracy:** ‚â•80% hazard detection accuracy vs. expert validation
- ‚úÖ **Memory Efficiency:** <3GB peak memory usage during inference
- ‚úÖ **Offline Capability:** 100% functionality without network connection
- ‚úÖ **Production Ready:** Integration with existing HazardHawk pipeline

---

**Document Status:** ‚úÖ Ready for Implementation  
**Architecture:** ‚úÖ Verified KMP Compatible  
**Dependencies:** ‚úÖ All Platform-Native  
**Estimated Duration:** 6-8 weeks  
**Confidence Level:** HIGH

---

*üèóÔ∏è Building safer construction sites with truly cross-platform AI*